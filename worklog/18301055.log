目前已完成：
任务1~任务6
任务5：安装hadoop，调整bin文件夹
运行spark，重设java路径变量
运行成功，结果如下（部分）：
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 3.0.0
      /_/

11:09：
使用anaconda，成功安装python依赖包

12:17：
疑似pycharm使用spark解决办法：
https://blog.csdn.net/Derek_Zhang_/article/details/83346829?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159349010019195188400497%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=159349010019195188400497&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v25-8-83346829.first_rank_v2_rank_v25&utm_term=pycharm%E4%BD%BF%E7%94%A8spark

13:52：
conda虚拟环境安装spark

14:40：
数据清理成功，生成清理后csv，开始安装虚拟机和spark集群
Xzh111xzh！！！

16:08：
开始学习ARIMA

day2：
上午：
虚拟机调试，完成虚拟机网络设置
初步学习了解ARIMA
