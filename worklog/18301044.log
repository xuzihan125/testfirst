2020.6.30 上午
完成任务1~任务7
spark可以正常启动
hadoop显示未知内部或外部命令，考虑是环境变量问题
但spark可以正常进入还未有解决方案
使用anaconda管理python环境成功安装依赖包和pyspark
但现在不能直接在命令行使用pyspark命令
考虑为计算机找不到python虚拟环境的命令
暂定解决方法为加虚拟环境的环境变量还未实现
或者在pycharm里写数据清洗代码
集群配置还有疑问留待下午解决

2020.6.30 下午
通过使用本地python环境解决了anaconda虚拟python环境和spark的使用问题
解决了Hadoop不能识别命令的问题
成功清洗了部分数据
安装了虚拟机
初步研究了ARIMA模型正在尝试python实现

2020.7.1
将Ubuntu安装至移动硬盘，并尝试搭建环境
成功配置了tomcat
开始进行前端的任务
学习html5等相关语法尝试写出简单的web并部署至tomcat
共同研究了ARIMA模型
